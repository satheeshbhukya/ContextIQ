# ğŸ“„ContextIQ - A Local RAG Based Secure Document Q&A System

ContextIQ is a fully local Retrieval-Augmented Generation (RAG) system that allows users to upload documents and ask AI-powered questions about their content â€” without using external APIs.
## ğŸŒŸ Features

- **Multi-format Document Support**: PDF, Word (.docx), Excel (.xlsx), PowerPoint (.pptx), and Text (.txt)
- **Semantic Search**: Uses sentence transformers and FAISS for efficient vector similarity search
- **AI-Powered Answers**: Leverages OpenVINO LLM (Phi-3) for accurate question answering
- **Interactive UI**: Clean Streamlit interface with conversation history
- **Source Attribution**: Shows which document sections were used to generate answers

## ğŸ—ï¸ Architecture

```
User Upload â†’ Document Parser â†’ Text Chunker â†’ Embedding Generator
                                                        â†“
User Question â†’ Query Embedder â†’ FAISS Search â†’ Context Retrieval â†’ LLM â†’ Answer
```

## ğŸ“‹ Prerequisites

- Python 3.8+

## ğŸš€ Installation

### 1. Clone the repository

```bash
git clone https://github.com/satheeshbhukya/ContextIQ.git
cd ContextIQ
```

### 2. Create virtual environment

```bash
python -m venv venv

# On Windows
venv\Scripts\activate

# On macOS/Linux
source venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```
### 4. Model download 
```bash
You must download OpenVINO Phi-3 model locally using python download_model.py
```

## ğŸ¯ Usage

### Run the application

```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

### Using the system

1. **Upload a document** using the sidebar file uploader
2. **Wait for processing** (you'll see a success message with chunk count)
3. **Ask questions** in the text input field
4. **View answers** with source attribution
5. **Check conversation history** to see previous Q&A pairs

## ğŸ“ Project Structure

```
ContextIQ/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ document_parser.py
â”‚   â”œâ”€â”€ text_processor.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â””â”€â”€ rag_engine.py
â”‚
â”œâ”€â”€ model/                âŒ NOT included in GitHub
â”‚   â””â”€â”€ phi-3-openvino/
â”‚
â””â”€â”€ data/                 (optional FAISS index storage)

```

## ğŸ”§ Configuration

### Adjustable Parameters

In the sidebar, you can adjust:
- **Number of chunks to retrieve** (1-10): More chunks = more context but slower

## ğŸ§ª Example Use Cases

1. **Research Papers**: Upload PDFs and ask about methodologies, findings, conclusions
2. **Legal Documents**: Query contracts, agreements for specific clauses
3. **Business Reports**: Extract insights from quarterly reports, presentations
4. **Technical Documentation**: Search for specific procedures, configurations
5. **Academic Notes**: Ask questions about study materials, lecture slides

## ğŸ› ï¸ Technical Stack

- **Frontend**: Streamlit
- **Document Processing**: PyMuPDF, python-docx, python-pptx, pandas
- **Text Processing**: LangChain
- **Embeddings**: Hugging Face sentence-transformers (all-MiniLM-L6-v2)
- **Vector Store**: FAISS
- **LLM**: OpenVINO Phi-3

## ğŸš€ Future Enhancements

- [ ] Support for image-based PDFs (OCR)
- [ ] Multi-document comparison queries
- [ ] Export conversation history
- [ ] Custom embedding model selection
- [ ] Response quality scoring
- [ ] Batch document processing
- [ ] Docker containerization
- [ ] Cloud deployment guide

## ğŸ“ License

MIT License - feel free to use this project for personal or commercial purposes.


## ğŸ“§ Contact

For questions or support, please open an issue on GitHub or contact [satheeshbhukyaa@gmail.com]

---

**â­ If you find this project useful, please consider giving it a star!**
